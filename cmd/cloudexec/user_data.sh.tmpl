#!/bin/bash
# shellcheck disable=SC1083
# shellcheck source=/dev/null
set -e
shopt -s inherit_errexit

########################################
# Setup env vars and constants

# Import env vars from user data
export DIGITALOCEAN_ACCESS_TOKEN={{.DigitalOceanToken}}
export AWS_ACCESS_KEY_ID={{.SpacesAccessKey}}
export AWS_SECRET_ACCESS_KEY={{.SpacesSecretKey}}
export AWS_DEFAULT_REGION={{.SpacesRegion}}
export SETUP_COMMANDS="{{.SetupCommands}}"
export RUN_COMMAND="{{.RunCommand}}"
export TIMEOUT="{{.Timeout}}"
export INPUT_DIRECTORY="{{.InputDirectory}}"

home="/root"
input_dir="${home}/${INPUT_DIRECTORY}"
output_dir="${input_dir}/output"
stdout_log="/tmp/cloudexec-stdout.log"
stderr_log="/tmp/cloudexec-stderr.log"

########################################
# Required setup

# Wait for unattended-upgr to finish install/upgrading stuff in the background
while fuser /var/lib/dpkg/lock >/dev/null 2>&1; do
	echo "Waiting for unattended-upgr to finish..."
	sleep 3
done

echo "Installing prereqs..."
export DEBIAN_FRONTEND=noninteractive
apt-get update
apt-get install -y jq s3cmd tmux python3-pip python3-venv unzip

# set hostname
current_hostname="$(hostname)"
if [[ ${current_hostname} != "cloudexec" ]]; then
	echo "Setting hostname..."
	echo "cloudexec" >/etc/hostname
	hostname -F /etc/hostname
fi

if ! command -v doctl >/dev/null 2>&1; then
	echo "Downloading doctl..."
	curl -fsSL -o /tmp/doctl-1.92.0-linux-amd64.tar.gz https://github.com/digitalocean/doctl/releases/download/v1.92.0/doctl-1.92.0-linux-amd64.tar.gz
	echo "Extracting doctl..."
	tar -xzf /tmp/doctl-1.92.0-linux-amd64.tar.gz -C /tmp
	echo "Installing doctl..."
	mv /tmp/doctl /usr/local/bin
	echo "Cleaning up..."
	rm /tmp/doctl-1.92.0-linux-amd64.tar.gz
fi

########################################
# Confirm required env vars are present

echo "Confirming this is a CloudExec droplet..."
TAGS=$(curl -s http://169.254.169.254/metadata/v1/tags)
echo "Droplet tags:"
echo "${TAGS}"
export JOB_ID=""
export USERNAME=""
export CLOUDEXEC=false
for tag in ${TAGS}; do
	if [[ ${tag} == "Purpose:cloudexec" ]]; then
		CLOUDEXEC=true
	elif [[ ${tag} == "Owner:"* ]]; then
		USERNAME=${tag#"Owner:"}
	elif [[ ${tag} == "Job:"* ]]; then
		JOB_ID=${tag#"Job:"}
	fi
done

export BUCKET_NAME="cloudexec-${USERNAME}"
echo "Using bucket ${BUCKET_NAME}"

echo "Setting up DigitalOcean credentials..."
# ensure these are set in the environment
if [[ -z ${DIGITALOCEAN_ACCESS_TOKEN} ]]; then
	echo "ERROR: DIGITALOCEAN_ACCESS_TOKEN is not set"
	echo "CloudExec will not be able to destroy the droplet"
	echo "on exit and you will incur charges."
	exit 1
fi

echo "Setting up S3 credentials..."
# Spaces uses the AWS S3 API
for var in AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_DEFAULT_REGION; do
	if [[ -z ${!var} ]]; then
		echo "${var} is not set, exiting..."
		exit 1
	fi
done

if [[ ${CLOUDEXEC} == false ]] || [[ ${USERNAME} == "" ]]; then
	echo "Not a CloudExec droplet, exiting..."
	# exit 1
fi

if [[ ${JOB_ID} == "" ]]; then
	echo "No job ID, exiting..."
	exit 1
fi

########################################
# Define helper functions

fmtDate() {
	date -d "@$1" "+%Y-%m-%d %H:%M:%S"
}

s3cmd() {
	command s3cmd --force --stop-on-error \
		--host="${AWS_DEFAULT_REGION}.digitaloceanspaces.com" \
		--host-bucket="%(bucket)s.${AWS_DEFAULT_REGION}.digitaloceanspaces.com" \
		"$@"
}

# Define a cleanup function that will be executed on signals or exit
export COMPLETED=false
export TIMEDOUT=false
cleanup() {
	echo "Workload finished, cleaning up droplet..."
	if [[ ${COMPLETED} == "false" && ${TIMEDOUT} == "false" ]]; then
		update_state "failed"
	fi

	output_files="$(ls -A "${output_dir}/")"
	if [[ -n ${output_files} ]]; then
		echo "Uploading results..."
		s3cmd put -r "${output_dir}"/* "s3://${BUCKET_NAME}/job-${JOB_ID}/output/"
	else
		echo "Skipping results upload, no files found in ${output_dir}"
	fi

	if [[ -s ${stdout_log} ]]; then
		echo
		echo "Dumping standard logs..."
		cat "${stdout_log}"
	else
		echo "No standard logs generated"
	fi

	if [[ -s ${stderr_log} ]]; then
		echo
		echo "Dumping error logs..."
		cat "${stderr_log}"
	else
		echo "No error logs generated"
	fi

	if [[ -s "/var/log/cloud-init-output.log" ]]; then
		echo "Uploading logs..."
		s3cmd put /var/log/cloud-init-output.log "s3://${BUCKET_NAME}/job-${JOB_ID}/logs/"
	else
		echo "No logs to upload.."
	fi

	echo
	echo "Destroying droplet..."
	THIS_DROPLET_ID=$(curl -s http://169.254.169.254/metadata/v1/id)
	curl -s -X DELETE \
		-H "Content-Type: application/json" \
		-H "Authorization: Bearer ${DIGITALOCEAN_ACCESS_TOKEN}" \
		"https://api.digitalocean.com/v2/droplets/${THIS_DROPLET_ID}"
}

update_state() {
	local new_status="$1"
	local updated_at
	updated_at=$(date +%s)
	pretty_updated_at=$(fmtDate "${updated_at}")
	echo
	echo "Setting new state to '${new_status}' at ${pretty_updated_at}"

	# Define state key and temporary files
	local state_key="state/state.json"
	local existing_state_file="/tmp/existing_state.json"
	local merged_state_file="/tmp/merged_state.json"

	# Download the existing state JSON from the Spaces bucket
	s3cmd get "s3://${BUCKET_NAME}/${state_key}" "${existing_state_file}"

	# Update the status and updated_at fields of the specified job using jq
	jq ".jobs |= map(if .id == ${JOB_ID} then .status = \"${new_status}\" | .updated_at = ${updated_at} | if \"${COMPLETED}\" == \"true\" then .completed_at = ${updated_at} else . end else . end)" "${existing_state_file}" >"${merged_state_file}"

	# Upload the merged state JSON to the Spaces bucket using s3cmd
	s3cmd put --acl-private --mime-type="application/json" "${merged_state_file}" "s3://${BUCKET_NAME}/${state_key}"

	# Clean up temporary files
	rm "${existing_state_file}" "${merged_state_file}"
}

# Set the trap to call the cleanup function on signals or exit
trap cleanup EXIT SIGHUP SIGINT SIGTERM

########################################
# Job-specific setup

echo "Running setup..."
eval "${SETUP_COMMANDS}"

echo "Downloading input archive..."
s3cmd get -r "s3://${BUCKET_NAME}/job-${JOB_ID}/input.zip" "${home}/"
if [[ ! -s "${home}/input.zip" ]]; then
	echo "Error: Failed to download input archive"
	exit 1
fi

echo "Unzipping input archive..."
unzip "${home}/input.zip" -d "${home}/"
if [[ ! -d ${input_dir} ]]; then
	echo "Error: Failed to unzip required ${input_dir} directory"
	exit 1
fi

mkdir -p "${input_dir}/output"
source "${home}/venv/bin/activate"

# Update state to running
update_state "running"

# Create a temporary file to track the completion of the task
exit_code_flag="/tmp/cloudexec-exit-code"

########################################
# Execute Job

# Use Ctrl-C to detach from the tmux session
echo "bind-key -n C-c detach" >"${home}/.tmux.conf"
# Run the tmux command in the background
echo "Attach to the tmux session with 'cloudexec attach'"
tmux_session="cloudexec"
wrapped_run_command="$(
	cat <<-EOF
		set_exit_code() { echo \$? > ${exit_code_flag}; };
		trap set_exit_code EXIT;
		cd ${input_dir}
		echo running workload from: ${input_dir}
		# Activates foundry, etc installations
		if [[ -f /.bashrc ]]
		then source /.bashrc
		fi
		( ${RUN_COMMAND} ) > >(tee -a ${stdout_log}) 2> >(tee -a ${stderr_log} >&2);
	EOF
)"
tmux new-session -d -s "${tmux_session}" "${wrapped_run_command}"

start_time=$(date "+%s")
pretty_start_time="$(fmtDate "${start_time}")"
end_time=$(("${start_time}" + TIMEOUT))
pretty_end_time="$(fmtDate "${end_time}")"
echo "Workload is running, timer started at ${pretty_start_time}, we'll time out at ${pretty_end_time}"

########################################
# Wait for job to finish

# Wait for the temporary file to be created
while true; do
	if [[ -s ${exit_code_flag} ]]; then
		exit_code="$(cat "${exit_code_flag}")"
		echo
		echo "CloudExec process has completed with exit code ${exit_code}"
		COMPLETED=true
		if [[ ${exit_code} == "0" ]]; then
			update_state "completed"
		else
			update_state "failed"
		fi
		# Remove the done flag temp file
		rm "${exit_code_flag}"
		break
	fi

	current_time=$(date "+%s")
	if [[ ${current_time} -gt ${end_time} ]]; then
		echo
		echo "timeout reached, shutting down"
		update_state "timedout"
		TIMEDOUT=true
		break
	fi

	sleep 1s
done
